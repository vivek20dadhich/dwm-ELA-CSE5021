{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20MAI0077\n",
    "### CSE5021\tData Warehousing and Mining\tELA\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rule Mining :-\n",
    "\n",
    "Association Rule Mining is used when you want to find an association between different objects in a set, find frequent patterns in a transaction database, relational databases or any other information repository. The applications of Association Rule Mining are found in Marketing, or Market Basket Analysis in retailing, clustering and classification.\n",
    "\n",
    "It can tell you what items do customers frequently buy together by generating a set of rules called Association Rules. In simple words, it gives you output as rules in form if this then that. Clients can use those rules for numerous marketing strategies ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Used: https://www.kaggle.com/ankitkatiyar91/apriori-algorithm/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "def find_frequent_1_itemsets(data, min_sup):\n",
    "    # Generate Candidate 1-itemsets\n",
    "    C0 = {}\n",
    "    for transaction in data:\n",
    "        for item in transaction:\n",
    "            if (item in C0):\n",
    "                C0[item] += 1\n",
    "            else:\n",
    "                C0[item] = 1\n",
    "\n",
    "    # Find the frequent 1-itemsets\n",
    "    L0 = []\n",
    "    for key, value in C0.items():\n",
    "        if (value >= min_sup):\n",
    "            L0.append([[key], value])\n",
    "\n",
    "    # Return the frequent 1-itemset\n",
    "    return sorted(L0)\n",
    "\n",
    "def find_frequent_k_itemsets(Ck, data, min_sup):\n",
    "    # Get the counts of itemsets in Ck\n",
    "    Ck_dict = {}\n",
    "    for i in range(len(Ck)):\n",
    "        for transaction in data:\n",
    "            if (set(Ck[i]) <= set(transaction)):\n",
    "                if (tuple(Ck[i]) in Ck_dict):\n",
    "                    Ck_dict[tuple(Ck[i])] += 1\n",
    "                else:\n",
    "                    Ck_dict[tuple(Ck[i])] = 1\n",
    "\n",
    "    # Find the frequent itemsests in Ck\n",
    "    Lk = []\n",
    "    for key, value in Ck_dict.items():\n",
    "        if (value >= min_sup):\n",
    "            Lk.append([list(key), value])\n",
    "\n",
    "    # Return the sorted frequent k-itemset\n",
    "    return sorted(Lk)\n",
    "\n",
    "def check_and_join(l1, l2):\n",
    "    c = []\n",
    "    k = len(l1)\n",
    "\n",
    "    if (k == 1):\n",
    "        c.extend(l1)\n",
    "        c.extend(l2)\n",
    "        return c\n",
    "\n",
    "    flag = True\n",
    "    for i in range(k-1):\n",
    "        if (l1[i] != l2[i]):\n",
    "            flag = False\n",
    "            break\n",
    "\n",
    "    if (flag):\n",
    "        c.extend(l1[0:k-2])\n",
    "\n",
    "        if (l1[k-1] < l2[k-1]):\n",
    "            c.extend(l1[k-1])\n",
    "            c.extend(l2[k-1])\n",
    "        else:\n",
    "            c.extend(l2[k-1])\n",
    "            c.extend(l1[k-1])\n",
    "\n",
    "    return c\n",
    "\n",
    "def has_infrequent_subset(c, l_prev):\n",
    "    # Create a dictionary of l_prev\n",
    "    l_prev_dict = {}\n",
    "    for i in range(len(l_prev)):\n",
    "        l_prev_dict[tuple(l_prev[i][0])] = 1\n",
    "\n",
    "    # Iterate over all subsets of c and check whether they are all present in l_prev\n",
    "    k = len(l_prev[0][0])\n",
    "    for subset in itertools.combinations(c, k):\n",
    "        if (subset not in l_prev_dict):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def apriori_gen(l_prev):\n",
    "    # Construct candidate k-itemset, Ck by joining and pruning itemsets in l_prev\n",
    "    Ck = []\n",
    "    for i in range(len(l_prev)-1):\n",
    "        for j in range(i+1, len(l_prev)):\n",
    "            c = check_and_join(l_prev[i][0], l_prev[j][0])\n",
    "            if (len(c) > 0 and has_infrequent_subset(c, l_prev) == False):\n",
    "                Ck.append(c)\n",
    "\n",
    "    return Ck\n",
    "\n",
    "# Sanity check of command line arguments\n",
    "if (len(sys.argv) != 4):\n",
    "    print (\"Usage: python main.py minimum_support_count_threshold min_confidence data_file_path\")\n",
    "    sys.exit()\n",
    "\n",
    "# Mimimum support count threshold\n",
    "min_sup = int(sys.argv[1])\n",
    "if (min_sup <= 0):\n",
    "    print (\"Error: Minimum support count value should be positive\")\n",
    "    sys.exit()\n",
    "\n",
    "min_conf = int(sys.argv[2])\n",
    "if (min_conf <= 0):\n",
    "    print (\"Error: Minimum confidence value should be positive\")\n",
    "    sys.exit()\n",
    "\n",
    "# Read the csv data file to a pandas dataframe\n",
    "df = pd.read_csv(sys.argv[3], header=None, names=['List of items'])\n",
    "\n",
    "# Store the dataframe as a list of lists\n",
    "data = []\n",
    "for _, row in df.iterrows():\n",
    "    data.append(sorted(row['List of items'].split(\",\")))\n",
    "\n",
    "# Find frequent 1-itemsets\n",
    "L0 = find_frequent_1_itemsets(data, min_sup)\n",
    "\n",
    "# Append L0 to the final frequent itemsets list\n",
    "L = []\n",
    "L.append(L0)\n",
    "\n",
    "# Iterate on k to find frequent k-itemsets\n",
    "k = 1\n",
    "while (len(L[k-1]) > 0):\n",
    "    Ck = apriori_gen(L[k-1])\n",
    "    Lk = find_frequent_k_itemsets(Ck, data, min_sup)\n",
    "    L.append(Lk)\n",
    "    k += 1\n",
    "\n",
    "# Print the frequent itemsets\n",
    "print ('{:30}{:15}'.format('Frequent Itemset', 'Support Count'))\n",
    "print (\"--------------------------------------------\")\n",
    "for freq_itemset in L:\n",
    "    for itemset in freq_itemset:\n",
    "        print ('{:30}{:5}'.format(str(itemset[0]), itemset[1]))\n",
    "\n",
    "# Store the support counts in dictionary\n",
    "sup_count = {}\n",
    "for freq_itemset in L:\n",
    "    for itemset in freq_itemset:\n",
    "        sup_count[tuple(itemset[0])] = itemset[1]\n",
    "\n",
    "# Find and print the association rules\n",
    "print (\"\\nAssociation rules:\")\n",
    "print (\"--------------------\")\n",
    "for freq_itemset in L:\n",
    "    for itemset in freq_itemset:\n",
    "        if (len(itemset[0]) <= 1):\n",
    "            continue\n",
    "\n",
    "        # Generate all the subsets of the current itemset\n",
    "        for i in range(1,len(itemset[0])):\n",
    "            for subset in itertools.combinations(itemset[0], i):\n",
    "                # Check the association rule confidence\n",
    "                if ((sup_count[subset] / sup_count[tuple(sorted(set(itemset[0]) - set(subset)))]) >= min_conf):\n",
    "                    print (subset,' => ', tuple(sorted(set(itemset[0]) - set(subset))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemset              Support Count  \n",
      "--------------------------------------------\n",
      "['BISCUIT']                       7\n",
      "['BOURNVITA']                     4\n",
      "['BREAD']                        13\n",
      "['COCK']                          3\n",
      "['COFFEE']                        8\n",
      "['CORNFLAKES']                    6\n",
      "['JAM']                           2\n",
      "['MAGGI']                         5\n",
      "['MILK']                          5\n",
      "['SUGER']                         6\n",
      "['TEA']                           7\n",
      "['BISCUIT', 'BREAD']              4\n",
      "['BISCUIT', 'COCK']               2\n",
      "['BISCUIT', 'COFFEE']             2\n",
      "['BISCUIT', 'CORNFLAKES']         3\n",
      "['BISCUIT', 'MAGGI']              2\n",
      "['BISCUIT', 'MILK']               2\n",
      "['BISCUIT', 'TEA']                2\n",
      "['BOURNVITA', 'BREAD']            3\n",
      "['BOURNVITA', 'SUGER']            2\n",
      "['BOURNVITA', 'TEA']              2\n",
      "['BREAD', 'COFFEE']               3\n",
      "['BREAD', 'JAM']                  2\n",
      "['BREAD', 'MAGGI']                3\n",
      "['BREAD', 'MILK']                 4\n",
      "['BREAD', 'SUGER']                4\n",
      "['BREAD', 'TEA']                  4\n",
      "['COCK', 'COFFEE']                3\n",
      "['COCK', 'CORNFLAKES']            2\n",
      "['COFFEE', 'CORNFLAKES']          4\n",
      "['COFFEE', 'SUGER']               4\n",
      "['CORNFLAKES', 'MILK']            2\n",
      "['CORNFLAKES', 'TEA']             2\n",
      "['JAM', 'MAGGI']                  2\n",
      "['MAGGI', 'TEA']                  4\n",
      "\n",
      "Association rules:\n",
      "--------------------\n",
      "('BREAD',)  =>  ('BISCUIT',)\n",
      "('BISCUIT',)  =>  ('COCK',)\n",
      "('COFFEE',)  =>  ('BISCUIT',)\n",
      "('BISCUIT',)  =>  ('CORNFLAKES',)\n",
      "('BISCUIT',)  =>  ('MAGGI',)\n",
      "('BISCUIT',)  =>  ('MILK',)\n",
      "('BISCUIT',)  =>  ('TEA',)\n",
      "('TEA',)  =>  ('BISCUIT',)\n",
      "('BREAD',)  =>  ('BOURNVITA',)\n",
      "('SUGER',)  =>  ('BOURNVITA',)\n",
      "('TEA',)  =>  ('BOURNVITA',)\n",
      "('BREAD',)  =>  ('COFFEE',)\n",
      "('BREAD',)  =>  ('JAM',)\n",
      "('BREAD',)  =>  ('MAGGI',)\n",
      "('BREAD',)  =>  ('MILK',)\n",
      "('BREAD',)  =>  ('SUGER',)\n",
      "('BREAD',)  =>  ('TEA',)\n",
      "('COFFEE',)  =>  ('COCK',)\n",
      "('CORNFLAKES',)  =>  ('COCK',)\n",
      "('COFFEE',)  =>  ('CORNFLAKES',)\n",
      "('COFFEE',)  =>  ('SUGER',)\n",
      "('CORNFLAKES',)  =>  ('MILK',)\n",
      "('TEA',)  =>  ('CORNFLAKES',)\n",
      "('MAGGI',)  =>  ('JAM',)\n",
      "('TEA',)  =>  ('MAGGI',)\n"
     ]
    }
   ],
   "source": [
    "%run main.py 2 1 data/GroceryStoreDataSet.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
